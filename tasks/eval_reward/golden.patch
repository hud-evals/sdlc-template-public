diff --git a/hud/agents/base.py b/hud/agents/base.py
index 3bd3e5a9..5d91cec7 100644
--- a/hud/agents/base.py
+++ b/hud/agents/base.py
@@ -834,7 +834,7 @@ def find_reward(result: MCPToolResult) -> float:
                 except json.JSONDecodeError:
                     pass
 
-    logger.error("Couldn't parse reward from result: %s", result)
+    logger.error("Couldn't parse reward from result: %s", str(result.structuredContent))
     return 0.0
 
 
diff --git a/hud/cli/eval.py b/hud/cli/eval.py
index 4e30df63..c2c6c906 100644
--- a/hud/cli/eval.py
+++ b/hud/cli/eval.py
@@ -447,9 +447,13 @@ def merge_cli(
             elif k in overrides and cli_args.get(k) is False:
                 del overrides[k]
 
-        # --full is a shortcut for --all
+        # --full is a shortcut for --all --auto-respond --max-steps 100
         if overrides.get("full"):
             overrides["all"] = True
+            if "auto_respond" not in overrides:
+                overrides["auto_respond"] = True
+            if "max_steps" not in overrides:
+                overrides["max_steps"] = 100
 
         if config:
             merged_agent_config = dict(self.agent_config)
diff --git a/hud/datasets/runner.py b/hud/datasets/runner.py
index 82086add..70174c53 100644
--- a/hud/datasets/runner.py
+++ b/hud/datasets/runner.py
@@ -106,8 +106,8 @@ async def run_dataset(
 
         # Create agent using AgentType.cls.create()
         agent = agent_type.cls.create(**final_agent_params)
-        result = await agent.run(ctx, max_steps=max_steps)
-        ctx.reward = result.reward
+        await agent.run(ctx, max_steps=max_steps)
+        # Reward is computed by EvalContext.__aexit__ from evaluate tools
 
     # For parallel execution, results are collected via ctx.results
     if hasattr(ctx, "results") and ctx.results:
@@ -213,6 +213,7 @@ async def run_single_task(
             ctx.metadata.update(metadata)
 
         result = await agent.run(ctx, max_steps=max_steps)
-        ctx.reward = result.reward
+        # Reward is computed by EvalContext.__aexit__ from evaluate tools
 
+    # Return the Trace (ctx.reward is set by EvalContext.__aexit__)
     return result
diff --git a/hud/environment/environment.py b/hud/environment/environment.py
index 11c9458d..4d11ef37 100644
--- a/hud/environment/environment.py
+++ b/hud/environment/environment.py
@@ -575,13 +575,19 @@ async def _execute_tool(self, name: str, arguments: dict[str, Any]) -> MCPToolRe
         if self._router.is_local(name):
             # Call tool manager directly to avoid FastMCP context requirement
             result = await self._tool_manager.call_tool(name, arguments)
-            return MCPToolResult(content=result.content, isError=False)
+            return MCPToolResult(
+                content=result.content, structuredContent=result.structured_content
+            )
 
         connection_name = self._router.get_connection(name)
         if connection_name:
             conn = self._connections[connection_name]
             result = await conn.call_tool(name, arguments)
-            return MCPToolResult(content=result.content, isError=result.isError)
+            return MCPToolResult(
+                content=result.content,
+                isError=result.isError,
+                structuredContent=result.structuredContent,
+            )
 
         raise ValueError(f"Tool not found: {name}")
 
diff --git a/hud/eval/context.py b/hud/eval/context.py
index 3efcee1c..0bf3f24f 100644
--- a/hud/eval/context.py
+++ b/hud/eval/context.py
@@ -660,7 +660,9 @@ async def __aexit__(
         # Disconnect environment (parent class) - also runs evaluate tools
         await super().__aexit__(exc_type, exc_val, exc_tb)
 
-        # Note: reward should already be set by the runner
+        # Evaluate tools determine the final reward
+        if hasattr(self, "_evaluate_reward") and self._evaluate_reward is not None:
+            self.reward = self._evaluate_reward
 
         # Reset context vars
         if self._token is not None:
